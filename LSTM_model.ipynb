{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1BSSYTdWWd4soan_o2I2QmxApV2EonpI8",
      "authorship_tag": "ABX9TyPcSoK8UuNJKt8aof/h8Dtt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NU009TyqCzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx0_o8a8pJzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import  BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h9W99y6pZDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = json.load(open('/content/drive/My Drive/training_data_sample.json'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_4wbTN7ubQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWZ2UdWUqOPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQUENCE_LENGTH = 128\n",
        "EMBEDDING_DIM = 16\n",
        "# ROWS_TO_SCAN = 2000000\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfH46v36I7iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []  # list of text samples\n",
        "labels_index = {}  # dictionary mapping label name to numeric id\n",
        "labels = []  # list of label ids\n",
        "label_id_counter = 1\n",
        "for i, row in enumerate(training_data):\n",
        "    # template_id = str(row[0]).zfill(12)\n",
        "    text = row[1].lower().strip('|')\n",
        "    text = text+ ' >'\n",
        "    print(text)\n",
        "    # start_index = len(template_id) + 2 + 1 + 2  # template_id, spaces, box_index, spaces\n",
        "    # box_index = 0\n",
        "    for j in range(0, len(text)):\n",
        "        char = text[j]\n",
        "        # note: it is critical that the number of spaces plus len(box_index) is >= the convolution width\n",
        "        texts.append(text[0:j])\n",
        "        if char in labels_index:\n",
        "            label_id = labels_index[char]\n",
        "        else:\n",
        "            label_id = label_id_counter\n",
        "            labels_index[char] = label_id\n",
        "            label_id_counter += 1\n",
        "        labels.append(label_id)\n",
        "        # if char == '|':\n",
        "        #     box_index += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy3kHtqmUBNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char_to_num(text):\n",
        "  char = []\n",
        "  for i in text:\n",
        "    char.append(labels_index[i])\n",
        "  return char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hVTX-5qtGq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def map_char_to_int(texts):\n",
        "#     char_counts = {}\n",
        "#     for text in texts:\n",
        "#         for char in text:\n",
        "#             char_counts[char] = char_counts[char] + 1 if char in char_counts else 1\n",
        "#     char_counts_sorted = sorted(char_counts.items(), reverse=True)\n",
        "#     char_to_int = {}\n",
        "#     for i, row in enumerate(char_counts_sorted):\n",
        "#         char_to_int[row[0]] = i + 1\n",
        "#     return char_to_int\n",
        "\n",
        "\n",
        "# for some reason these two functions are way faster than the keras char-level tokenizer\n",
        "def texts_to_sequences(texts, labels_index):\n",
        "    sequences = []\n",
        "    for text in texts:\n",
        "        sequences.append([labels_index[char] for char in text])\n",
        "    return sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCNwsWL4tdGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# char_to_int = map_char_to_int(texts)\n",
        "sequences = texts_to_sequences(texts, labels_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycAvwdsBCiAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pad_sequences(sequences,  maxlen=128)\n",
        "labels = np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv7FljpNuIWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "# validation set can be much smaller if we use a lot of data (source: andrew ng on coursera video)\n",
        "validation_ratio = 0.001 if data.shape[0] < 1000000 else 0.02\n",
        "num_validation_samples = int(validation_ratio * data.shape[0])\n",
        "\n",
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjiADNGGp1V1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/params.json', 'w') as handle:\n",
        "    json.dump({\n",
        "        'sequence_length': SEQUENCE_LENGTH,\n",
        "        'embedding_dim': EMBEDDING_DIM,\n",
        "        'num_rows_used': len(sequences),\n",
        "        'num_epochs': NUM_EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'labels_index': labels_index\n",
        "    }, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PadfRvxtc8Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7kZZ3HuaJrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EH1aE8mIn8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(57, 128, input_shape=(128,)))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(256))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Conv1D(1024, 5, activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(2))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Conv1D(1024, 5, activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(2))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Conv1D(1024, 5, activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(2))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Conv1D(1024, 5, activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Dense(1024, activation='relu'))\n",
        "# model.add(MaxPooling1D(16))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Conv1D(1024, 5, activation='relu', padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(len(labels_index)+1, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='rmsprop', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idH60Oh5KGAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSTNv79PKfUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sv0zH8HKVmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=MODEL_PATH + '/model_2.h5', verbose=1, save_best_only=True)\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=NUM_EPOCHS, batch_size=128, callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6g0p6UlTFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjUqg3izmgVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = json.load(open('/content/drive/My Drive/params.json'))\n",
        "SEQUENCE_LENGTH = params['sequence_length']\n",
        "int_to_char = {v: k for k, v in params['labels_index'].items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZd-7sirMnHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = 'coderschool'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdOV1lMgZSue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = sample.lower()\n",
        "for i in range(300):\n",
        "  temp = char_to_num(res)\n",
        "  data = pad_sequences([temp],  maxlen=SEQUENCE_LENGTH)[0]\n",
        "  data = np.expand_dims(data, axis = 0)\n",
        "  y = model.predict(data)\n",
        "  y = np.argmax(y)\n",
        "  char = int_to_char[y]\n",
        "  if char == '>':\n",
        "    break\n",
        "  res += char\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuHHm65G3AoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.saved_model.save(model, \"/content/drive/My Drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwS35ldqNYuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/model_final_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}